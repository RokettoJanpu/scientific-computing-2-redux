\documentclass{article}
\usepackage{amsfonts, amsthm, amsmath, amssymb, mathtools, ulem, mathrsfs, physics, esint, siunitx, tikz-cd}
\usepackage{pdfpages, fullpage, color, microtype, cancel, textcomp, markdown, hyperref, graphicx}
\usepackage{enumitem}
\usepackage{algorithm}
\usepackage{algpseudocode}
\graphicspath{{./images/}}
\usepackage[english]{babel}
\usepackage[autostyle, english=american]{csquotes}
\MakeOuterQuote{"}
\usepackage{xparse}
\usepackage{tikz}

\usepackage{calligra}
\DeclareMathAlphabet{\mathcalligra}{T1}{calligra}{m}{n}
\DeclareFontShape{T1}{calligra}{m}{n}{<->s*[2.2]callig15}{}
\newcommand{\script}[1]{\ensuremath{\mathcalligra{#1}}}
\newcommand{\scr}{\script r}

% fonts
\def\mbb#1{\mathbb{#1}}
\def\mfk#1{\mathfrak{#1}}
\def\mbf#1{\mathbf{#1}}
\def\tbf#1{\textbf{#1}}

% common bold letters
\def\bP{\mbb{P}}
\def\bC{\mbb{C}}
\def\bH{\mbb{H}}
\def\bI{\mbb{I}}
\def\bR{\mbb{R}}
\def\bQ{\mbb{Q}}
\def\bZ{\mbb{Z}}
\def\bN{\mbb{N}}

% brackets
\newcommand{\br}[1]{\left(#1\right)}
\newcommand{\sbr}[1]{\left[#1\right]}
\newcommand{\brc}[1]{\left\{#1\right\}}
\newcommand{\lbr}[1]{\left\langle#1\right\rangle}

% vectors
\renewcommand{\i}{\hat{\imath}}
\renewcommand{\j}{\hat{\jmath}}
\renewcommand{\k}{\hat{k}}
\newcommand{\proj}[2]{\text{proj}_{#2}\br{#1}}
\newcommand{\m}[2][b]{\begin{#1matrix}#2\end{#1matrix}}
\newcommand{\arr}[3][\sbr]{#1{\begin{array}{#2}#3\end{array}}}

% misc
\NewDocumentCommand{\seq}{O{n} O{1} O{\infty} m}{\br{#4}_{{#1}={#2}}^{#3}}
\NewDocumentCommand{\app}{O{x} O{\infty}}{\xrightarrow{#1\to#2}}
\newcommand{\sm}{\setminus}
\newcommand{\sse}{\subseteq}
\renewcommand{\ss}{\subset}
\newcommand{\vn}{\varnothing}
\newcommand{\lc}{\epsilon_{ijk}}
\newcommand{\ep}{\epsilon}
\newcommand{\vp}{\varphi}
\renewcommand{\th}{\theta}
\newcommand{\cjg}[1]{\overline{#1}}
\newcommand{\inv}{^{-1}}
\DeclareMathOperator{\im}{im}
\DeclareMathOperator{\id}{id}
\newcommand{\ans}{\tbf{Ans. }}
\newcommand{\pf}{\tbf{Pf. }}
\newcommand{\imp}{\implies}
\newcommand{\impleft}{\reflectbox{$\implies$}}
\newcommand{\ck}{\frac1{4\pi\ep_0}}
\newcommand{\ckb}{4\pi\ep_0}
\newcommand{\sto}{\longrightarrow}
\DeclareMathOperator{\cl}{cl}
\DeclareMathOperator{\intt}{int}
\DeclareMathOperator{\bd}{bd}
\DeclareMathOperator{\Span}{span}
\newcommand{\floor}[1]{\left\lfloor#1\right\rfloor}
\newcommand{\ceil}[1]{\left\lceil#1\right\rceil}
\newcommand{\fxn}[5]{#1:\begin{array}{rcl}#2&\longrightarrow & #3\\[-0.5mm]#4&\longmapsto &#5\end{array}}
\newcommand{\sep}[1][.5cm]{\vspace{#1}}
\DeclareMathOperator{\card}{card}
\renewcommand{\ip}[2]{\lbr{#1,#2}}
\renewcommand{\bar}{\overline}
\DeclareMathOperator{\cis}{cis}
\DeclareMathOperator{\Arg}{Arg}
\newcommand{\ptl}{\partial}

% title
\title{Scientific Computing HW 7}
\author{Ryan Chen}
%\date{\today}
\setlength{\parindent}{0pt}


\begin{document}
	
\maketitle



\begin{enumerate}
	


\item We must compute (we will temporarily drop the dependence of $v$ on $k_x,k_y$)
\[Av = \frac{1}{h^2}(4U_Pv-U_Wv-U_Ev-U_Nv-U_Sv)\]
Using the identity $\sin(x\pm y)=\sin x\cos y\pm\cos x\sin y$,
\begin{align*}
	U_Pv &= \sin k_xhi\sin k_yhj \\
	U_Wv &= \sin k_xh(i-1)\sin k_yhj = [\sin k_xhi\cos k_xh-\cos k_xhi\sin k_xh]\sin k_yhj \\
	U_Ev &= \sin k_xh(i+1)\sin k_yhj = [\sin k_xhi\cos k_xh+\cos k_xhi\sin k_xh]\sin k_yhj \\
	U_Nv &= \sin k_xhi\sin k_yh(j+1) = \sin k_xhi[\sin k_yhj\cos k_yh + \cos k_yhj\sin k_yh] \\
	U_Sv &= \sin k_xhi\sin k_yh(j-1) = \sin k_xhi[\sin k_yhj\cos k_yh - \cos k_yhj\sin k_yh] \\
\end{align*}
Thus
\begin{align*}
	U_Wv+U_Ev+U_Nv+U_Sv &= [\sin k_xhi\cos k_xh-\cos k_xhi\sin k_xh]\sin k_yhj \\
							&- [\sin k_xhi\cos k_xh+\cos k_xhi\sin k_xh]\sin k_yhj \\
							&- \sin k_xhi[\sin k_yhj\cos k_yh + \cos k_yhj\sin k_yh] \\
							&- \sin k_xhi[\sin k_yhj\cos k_yh - \cos k_yhj\sin k_yh] \\
						&= -2\sin k_xhi\sin k_yhj\cos k_xh - 2\sin k_xhi\sin k_yhj\cos k_yh \\
						&= -2\sin k_xhi\sin k_yhj(\cos k_xh+\cos k_yh)
\end{align*}
At last we find the eigenvalues $\lambda=\lambda(k_x,k_y)$.
\[Av_{k_x,k_y} = \underbrace{\frac{1}{h^2}[4-2(\cos k_xh+\cos k_yh)]}_{\lambda(k_x,k_y)}\sin k_xhi\sin k_yhj=\lambda(k_x,k_y)v_{k_x,k_y}\]

To estimate the smallest and largest eigenvalues of $A$, first write
\[\lambda = N^2\sbr{4-2\br{\cos\frac{n\pi}{N}+\cos\frac{m\pi}{N}}}\]
We see $\lambda$ is maximized at $n,m=N-1$, and $\cos\frac{(N-1)\pi}{N}\sim1$, hence $\lambda_{max}\sim 8N^2$. We also see $\lambda$ is minimized at $n,m=1$, and using the fact $\cos x\sim 1-\frac12x^2$ for $x\sim0$, we have $\cos\frac{\pi}{N}\sim 1-\frac{\pi^2}{N^2}$, hence $\lambda_{min}\sim N^2\sbr{4-4\br{1-\frac{\pi^2}{N^2}}}=4\pi^2$. Lastly, the condition number is
\[\kappa(A) = \abs{\frac{\lambda_{max}}{\lambda_{min}}} \sim \frac{4N^2}{\pi^2}\]

	
\item 

\begin{enumerate}
	
	
	\item Multiplying the BVP by $-1$ and integrating it, we find $k(x)u'=M$ for some constant $M$, i.e. $u'=\frac{M}{k(x)}$. The solution is then
	$$u(x) = u_a + \int_a^x \frac{M}{k(s)}ds$$
	If $x\le c$ then
	$$u(x) = u_a + \int_a^x \frac{M}{k_1}ds = u_a + \frac{M}{k_1}(x-a)$$
	If $x>c$ then
	$$u(x) = u_a + \int_a^c \frac{M}{k(s)}ds + \int_c^x \frac{M}{k(s)}ds
	= u_a + \int_a^c \frac{M}{k_1}ds + \int_c^x \frac{M}{k_2}ds
	= u_a + \frac{M}{k_1}(c - a) + \frac{M}{k_2}(x - c)$$
	Apply BCs.
	$$u_b = u(b)
	= u_a + \frac{M}{k_1}(c - a) + \frac{M}{k_2}(b - c)
	= u_a + M\sbr{\frac{c-a}{k_1} + \frac{b-c}{k_2}}
	\imp M = \frac{u_b-u_a}{\frac{c-a}{k_1}+\frac{b-c}{k_2}}$$
	In summary, the solution is
	$$u(x) = 
	\begin{cases}
		u_a + \frac{M}{k_1}(x-a), & x\le c\\
		u_a + \frac{M}{k_1}(c - a) + \frac{M}{k_2}(x - c), & x>c
	\end{cases}
	\quad \text{ where }
	\quad M = \frac{u_b-u_a}{\frac{c-a}{k_1}+\frac{b-c}{k_2}}$$
	
	
	\item Given the parameters, we solve for the values of the 9 mesh points shown below.
	\begin{center}
		\includegraphics[scale=.09]{hw7 q2 mesh}
	\end{center}
	
	The finite difference scheme is
	$$L_hu_P = -\frac{1}{h^2}\sbr{k_wu_W + k_eu_E - (k_e + k_w)u_P} = 0
	\imp -(k_w + k_e)u_P + k_wu_W + k_eu_E = 0$$
	Applying the scheme to each mesh point, we obtain a linear system.
	\begin{center}
		\includegraphics[scale=.09]{hw7 q2 full}
	\end{center}
	
	We solve it and plot the numerical solution $u$ along with the exact solution from part (a). In this case the solutions agree exactly.
	
	Code: \url{https://github.com/RokettoJanpu/scientific-computing-2-redux/blob/main/hw7q2.ipynb}
	\begin{center}
		\includegraphics[scale=.5]{hw7 q2 plot}
	\end{center}
	
	
\end{enumerate}



\item Code: \url{https://github.com/RokettoJanpu/Scientific-Computing-2/blob/main/hw7q2.ipynb}


\includegraphics[scale=.35]{hw7 q3 shape 1}
\includegraphics[scale=.35]{hw7 q3 shape 2}
\includegraphics[scale=.35]{hw7 q3 shape 3}
\sep



\item

\begin{enumerate}
	
	
	\item Multiply the BVP by $w$ and integrate over $[0,1]$.
	\[-\int_0^1 w(x)u''(x)dx = \int_0^1 w(x)f(x)dx\]
	Integrating by parts and using the fact $w(0)=w(1)=0$, the LHS is
	\[-\int_0^1 w(x)u''(x)dx = -w(x)u(x)\eval_0^1 + \int_0^1 w'(x)u(x)dx = \int_0^1 w'(x)u(x)dx\]
	Thus we obtain an integral equation for $u$.
	\[\int_0^1 w'(x)u(x)dx = \int_0^1 w(x)f(x)dx\]
	
	
	\item First define other basis functions
	$$\vp_0(x) :=
	\begin{cases}
		0, & x\ge x_1\\
		\frac{x_1-x}{x_1}, & x<x_1
	\end{cases},
	\quad \vp_{N+1}(x) :=
	\begin{cases}
		0, & x\le x_N\\
		\frac{x-x_N}{x_{N+1}-x_N}, & x>x_N
	\end{cases}$$
	When computing the stiffness matrix (with rows and columns starting at 0 instead of 1)
	$$A_{ij} = \int_0^1\vp_i'(x)\vp_j'(x)dx$$
	we will use the fact it is symmetric. First compute
	$$\vp_i'(x) =
	\begin{cases}
		0, & x<x_{i-1} \text{ or } x>x_{i+1}\\
		\frac{1}{x_i-x_{i-1}}, & x_{i-1}<x<x_i\\
		-\frac{1}{x_{i+1}-x_i}, & x_i<x<x_{i+1}
	\end{cases},
	\quad \vp_0'(x) =
	\begin{cases}
		0, & x>x_1\\
		-\frac{1}{x_1}, & x<x_1
	\end{cases},
	\quad \vp_{N+1}'(x) =
	\begin{cases}
		0, & x<x_N\\
		\frac{1}{x_{N+1}-x_N}, & x>x_N
	\end{cases}$$
	
	
	Fix $1\le i\le N$ and examine cases of the value of $j$.
	
	\begin{itemize}
		
		\item If $j=i$ then
		$$\vp_i'(x)\vp_j'(x) =
		\begin{cases}
			0, & x< x_{i-1} \text{ or } x> x_{i+1}\\
			\frac{1}{(x_i-x_{i-1})^2}, & x_{i-1}<x<x_i\\
			\frac{1}{(x_{i+1}-x_i)^2}, & x_i<x<x_{i+1}
		\end{cases}$$
		hence
		$$A_{ij} = \frac{x_i-x_{i-1}}{(x_i-x_{i-1})^2} + \frac{x_{i+1}-x_i}{(x_{i+1}-x_i)^2}
		= \frac{1}{x_i-x_{i-1}} + \frac{1}{x_{i+1}-x_i}$$
		
		\item If $j=i+1$ then
		$$\vp_i'(x)\vp_j'(x) =
		\begin{cases}
			0, & x< x_i \text{ or } x> x_{i+1}\\
			-\frac{1}{(x_{i+1}-x_{i})^2}, & x_i<x<x_{i+1}\\
		\end{cases}$$
		hence
		$$A_{ij} = -\frac{x_{i+1}-x_i}{(x_{i+1}-x_{i})^2} = -\frac{1}{x_{i+1}-x_{i}}$$
		In particular, if $j=i-1$ then $i=j+1$, so that by symmetry
		$$A_{ij} = A_{ji} = -\frac{1}{x_{j+1}-x_j} = -\frac{1}{x_i-x_{i-1}}$$
		
		\item $j\ge i+2$ then $\vp_i'\vp_j'=0$ hence $A_{ij}=0$. In particular, if $j\le i-2$ then $i\ge j+2$, so that by symmetry $A_{ij}=A_{ji}=0$.
		
	\end{itemize}
	
	Now examine cases for $i=0$.
	\begin{itemize}
		
		\item If $j=0$,
		$$\vp_0'(x)^2 =
		\begin{cases}
			0, & x>x_1\\
			\frac{1}{x_1^2}, & x<x_1
		\end{cases}$$
		hence $A_{00}=\frac{1}{x_1}$.
		
		\item If $j=1$, by symmetry $A_{01} = A_{10} = -\frac{1}{x_1-x_0} = -\frac{1}{x_1}$.
		
		\item If $2\le j\le N+1$ then $\vp_0'\vp_j'=0$, hence $A_{0j}=0$.
		
	\end{itemize}
	
	Examine cases for $i=N+1$.
	\begin{itemize}
		
		\item If $0\le j\le N-1$ then $\vp_{N+1}'\vp_j'=0$, hence $A_{N+1,j}=0$.
		
		\item If $j=N$, by symmetry $A_{N+1,N} = A_{N,N+1} = -\frac{1}{x_{N+1}-x_N}$.
		
		\item If $j=N+1$,
		$$\vp_{N+1}'(x)^2 =
		\begin{cases}
			0, & x<x_N\\
			\frac{1}{(x_{N+1}-x_N)^2}, & x>x_N
		\end{cases}$$
		hence $A_{N+1,N+1}=\frac{1}{x_{N+1}-x_N}$.
		
	\end{itemize}
	
	To summarize, for $1\le i\le N$,
	$$A_{ij} = 
	\begin{cases}
		\frac{1}{x_i-x_{i-1}} + \frac{1}{x_{i+1}-x_i}, & j=i\\
		-\frac{1}{x_{i+1}-x_{i}}, & j=i+1\\
		-\frac{1}{x_i-x_{i-1}}, & j=i-1\\
		0, & j\le i-2 \text{ or } j\ge i+2
	\end{cases}$$
	For $i=0$,
	$$A_{0j} =
	\begin{cases}
		\frac{1}{x_1}, & j=0\\
		-\frac{1}{x_1}, & j=1\\
		0, & 2\le j\le N+1
	\end{cases}$$
	For $i=N+1$,
	$$A_{N+1,j} =
	\begin{cases}
		0, & 0\le j\le N-1\\
		-\frac{1}{x_{N+1}-x_N}, & j=N\\
		\frac{1}{x_{N+1}-x_N}, & j=N+1
	\end{cases}$$
	
	We now compute the load vector $b$. For $1\le i\le N$, we approximate
	$$\int_0^1\vp_i(x)f(x)dx = \int_{x_{i-1}}^{x_i}\vp_ifdx + \int_{x_i}^{x_{i+1}}\vp_ifdx
	\approx f\br{\frac{x_{i-1}+x_{i}}2}\frac{x_{i}-x_{i-1}}2 + f\br{\frac{x_{i}+x_{i+1}}2}\frac{x_{i+1}-x_{i}}2$$
	From the BCs, set the vector $u_D$ with components
	$$(u_D)_i :=
	\begin{cases}
		1, & i=0 \text{ or } i=N+1\\
		0, & 1\le i\le N
	\end{cases}$$
	so that
	$$Au_D =
	\m{\frac{1}{x_1} \\ -\frac{1}{x_1} \\ 0 \\ \vdots \\ 0 \\ -\frac{1}{x_{N+1}-x_N} \\ \frac{1}{x_{N+1}-x_N}}$$
	Thus for $1\le i\le N$,
	$$b_i = -(Au_D)_i + \int_0^1\vp_ifdx \approx
	\begin{cases}
		\frac{1}{x_1} + f\br{\frac{x_{1}}2}\frac{x_{1}}2 + f\br{\frac{x_{1}+x_{2}}2}\frac{x_{2}-x_{1}}2, & i=1\\
		f\br{\frac{x_{i-1}+x_{i}}2}\frac{x_{i}-x_{i-1}}2 + f\br{\frac{x_{i}+x_{i+1}}2}\frac{x_{i+1}-x_{i}}2, & 2\le i\le N-1\\
		\frac{1}{x_{N+1}-x_N} + f\br{\frac{x_{N-1}+x_{N}}2}\frac{x_{N}-x_{N-1}}2 + f\br{\frac{x_{N}+x_{N+1}}2}\frac{x_{N+1}-x_{N}}2, & i=N\\
	\end{cases}$$
	
	
	\item Solutions for FEM and FDM coincide if the mesh stepsize is constant.


\end{enumerate}



\end{enumerate}

	
\end{document}